{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation for interaction selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "p = 10\n",
    "X = np.random.choice([0, 1], (n, p))\n",
    "y = X[:, 0] * X[:, 1] + X[:, 2] * X[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = rfr(bootstrap=True, n_estimators=300)\n",
    "rf.fit(X,  y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import _tree\n",
    "def all_tree_signed_paths(dtree, root_node_id=0):\n",
    "    \"\"\"\n",
    "    Get all the individual tree signed paths from root node to the leaves\n",
    "    for a decision tree classifier object [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dtree : DecisionTreeClassifier object\n",
    "        An individual decision tree classifier object generated from a\n",
    "        fitted RandomForestClassifier object in scikit learn.\n",
    "\n",
    "    root_node_id : int, optional (default=0)\n",
    "        The index of the root node of the tree. Should be set as default to\n",
    "        0 and not changed by the user\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    paths : list\n",
    "        Return a list containing 1d numpy arrays of the node paths\n",
    "        taken from the root node to the leaf in the decsion tree\n",
    "        classifier. There is an individual array for each\n",
    "        leaf node in the decision tree.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "        To obtain a deterministic behaviour during fitting,\n",
    "        ``random_state`` has to be fixed.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "        .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_breast_cancer\n",
    "    >>> from sklearn.model_selection import train_test_split\n",
    "    >>> from sklearn.ensemble import RandomForestClassifier\n",
    "    >>> raw_data = load_breast_cancer()\n",
    "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
    "        raw_data.data, raw_data.target, train_size=0.9,\n",
    "        random_state=2017)\n",
    "    >>> rf = RandomForestClassifier(\n",
    "        n_estimators=3, random_state=random_state_classifier)\n",
    "    >>> rf.fit(X=X_train, y=y_train)\n",
    "    >>> estimator0 = rf.estimators_[0]\n",
    "    >>> tree_dat0 = all_tree_paths(dtree = estimator0,\n",
    "                                   root_node_id = 0)\n",
    "    >>> tree_dat0\n",
    "    ...                             # doctest: +SKIP\n",
    "    ...\n",
    "    \"\"\"\n",
    "    #TODO: use the decision path function in sklearn to optimize the code\n",
    "    # sanity CHECK\n",
    "    #if type(dtree) != sklearn.tree.DecisionTreeClassifier:\n",
    "    #    raise ValueError('dtree type is supposed to be sklearn.tree.tree.DecisionTreeClassifier but got %s'%type(dtree))\n",
    "\n",
    "    # Use these lists to parse the tree structure\n",
    "    children_left = dtree.tree_.children_left\n",
    "    children_right = dtree.tree_.children_right\n",
    "\n",
    "    if root_node_id is None:\n",
    "        paths = []\n",
    "\n",
    "    if root_node_id == _tree.TREE_LEAF:\n",
    "        raise ValueError(\"Invalid node_id %s\" % _tree.TREE_LEAF)\n",
    "\n",
    "    # if left/right is None we'll get empty list anyway\n",
    "    feature_id = dtree.tree_.feature[root_node_id] \n",
    "    if children_left[root_node_id] != _tree.TREE_LEAF:\n",
    "        \n",
    "        \n",
    "        paths_left = [[str(feature_id) + '_L'] + l\n",
    "                 for l in all_tree_signed_paths(dtree, children_left[root_node_id])]\n",
    "        paths_right = [[str(feature_id) + '_R'] + l\n",
    "                 for l in all_tree_signed_paths(dtree, children_right[root_node_id])]\n",
    "        paths = paths_left + paths_right\n",
    "    else:\n",
    "        paths = [[]]\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for tree in rf.estimators_:\n",
    "    paths += all_tree_signed_paths(tree, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prevalance(paths, patterns):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for path in paths:\n",
    "        count += all(x in path for x in patterns) * 2 **(- len(path))\n",
    "        total += 2 **(- len(path))\n",
    "    return count * 1.0 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42583333333333334 0.42583333333333334\n",
      "0.32416666666666666 0.32416666666666666\n",
      "0.3545833333333333 0.3545833333333333\n",
      "0.3954166666666667 0.3954166666666667\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for feature_id in range(10):\n",
    "    print(prevalance(paths, ['{}_L'.format(feature_id)]), prevalance(paths, ['{}_R'.format(feature_id)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Although, all four features 1,2,3,4 should be totally symmetric, their appearance in the paths is not the same. This shows that those simulations do not exactly correspond to the population version. Maybe we should restrict the depth of the tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25, 0.0, 0.07416666666666667, 0.17583333333333334)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalance(paths, ['0_R', '1_R']),prevalance(paths, ['0_L', '1_L']),prevalance(paths, ['0_L', '1_R']),prevalance(paths, ['0_R', '1_L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** It is nice to see that the 25% which we get from the calculations do exactly pop up here. Also the 0% is what you would get in the population setting calculation. However, from the population perspective ('0_L', '1_R') and ('0_R','1_L') should be completely symmetric appear with probability 0.5^3 = 12.5%. We don't see this limit here. Why do we see it for the first two cases but not for the last two? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25, 0.0, 0.14541666666666667, 0.10458333333333333)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalance(paths, ['2_R', '3_R']),prevalance(paths, ['2_L', '3_L']),prevalance(paths, ['2_L', '3_R']),prevalance(paths, ['2_R', '3_L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18416666666666667,\n",
       " 0.14708333333333334,\n",
       " 0.14541666666666667,\n",
       " 0.18583333333333332)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalance(paths, ['0_R', '3_R']),prevalance(paths, ['0_L', '3_L']),prevalance(paths, ['0_L', '3_R']),prevalance(paths, ['0_R', '3_L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Here the theoretical population limit should be 0.5^6 + 0.5^3 ~ 14% for the first pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.139375, 0.139375, 0.14104166666666668, 0.13770833333333332)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalance(paths, ['1_R', '3_R']),prevalance(paths, ['1_L', '3_L']),prevalance(paths, ['1_L', '3_R']),prevalance(paths, ['1_R', '3_L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** These probabilities should, in the population case, be the same as above, but they are not. However, the fact that the first two probabilities are the same, seems to indicate that they correspond to some limit. Their theoretical value should be 0.5^6 + 0.5^3 = 0.140625. The observed value is similar fut not the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** One source of bias in these simulations, compared to out theoretical results, might be that we are also averaging over paths within the same tree. These paths are not independent. Out results apply to an individual path, so it might make more sense to only randomly pick one path per tree and then average over trees. Or, alternatively, only pick one path at all and than average over i.i.d. replications of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11, 0.10125, 0.10833333333333334, 0.10291666666666667)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalance(paths, ['1_R', '2_R']),prevalance(paths, ['1_L', '2_L']),prevalance(paths, ['1_L', '2_R']),prevalance(paths, ['1_R', '2_L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12895833333333334,\n",
       " 0.17479166666666668,\n",
       " 0.16770833333333332,\n",
       " 0.13604166666666667)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalance(paths, ['0_R', '2_R']),prevalance(paths, ['0_L', '2_L']),prevalance(paths, ['0_L', '2_R']),prevalance(paths, ['0_R', '2_L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
